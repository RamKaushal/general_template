{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f34f3a82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in c:\\users\\ramka\\downloads\\fdfs cnn\\pracice\\lib\\site-packages (4.7.0.68)\n",
      "Requirement already satisfied: numpy>=1.19.3 in c:\\users\\ramka\\downloads\\fdfs cnn\\pracice\\lib\\site-packages (from opencv-python) (1.23.5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 20.3.3; however, version 22.3.1 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\ramka\\Downloads\\FDFS CNN\\pracice\\Scripts\\python.exe -m pip install --upgrade pip' command.\n",
      "ERROR: Could not find a version that satisfies the requirement file_writer\n",
      "ERROR: No matching distribution found for file_writer\n",
      "WARNING: You are using pip version 20.3.3; however, version 22.3.1 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\ramka\\Downloads\\FDFS CNN\\pracice\\Scripts\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python\n",
    "!pip install file_writer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5e265dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import urllib.request as req\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import shutil\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36561965",
   "metadata": {},
   "outputs": [],
   "source": [
    "SOURCE_URL = r\"C:\\Users\\ramka\\Downloads\\archive (19).zip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0280c1d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "DESTINATION = \"data\"\n",
    "data_file  = \"data.zip\"\n",
    "\n",
    "DESTINATION_ZIP_PATH = os.path.join(DESTINATION,data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e77d7986",
   "metadata": {},
   "outputs": [],
   "source": [
    "from zipfile import Zipfile\n",
    "\n",
    "with Zipfile(filename,\"r\") as zip_f:\n",
    "    zip_f.extractall\n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "905a88c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_DATA_DIR = ['Cat','Dog']\n",
    "PARENT = r'C:\\Users\\ramka\\Downloads\\FDFS CNN\\general_template\\research_env\\data\\kagglecatsanddogs_3367a\\PetImages'\n",
    "bad_data =r\"C:\\Users\\ramka\\Downloads\\FDFS CNN\\general_template\\research_env\\bad_data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "48e38b1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ramka\\Downloads\\FDFS CNN\\general_template\\research_env\\data\\kagglecatsanddogs_3367a\\PetImages\\Cat\\Thumbs.db is corrupted\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ramka\\downloads\\fdfs cnn\\pracice\\lib\\site-packages\\PIL\\TiffImagePlugin.py:858: UserWarning: Truncated File Read\n",
      "  warnings.warn(str(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ramka\\Downloads\\FDFS CNN\\general_template\\research_env\\data\\kagglecatsanddogs_3367a\\PetImages\\Dog\\Thumbs.db is corrupted\n"
     ]
    }
   ],
   "source": [
    "for i in os.listdir(PARENT):\n",
    "    fullpath = os.path.join(PARENT,i)\n",
    "    for j in os.listdir(fullpath):\n",
    "        img_full_path  = os.path.join(fullpath,j)\n",
    "       \n",
    "        try:\n",
    "            img = Image.open(img_full_path)\n",
    "            img.verify()\n",
    "            #print(\"{} is verified\".format(img_full_path))\n",
    "        except:\n",
    "            print(\"{} is corrupted\".format(img_full_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e221e2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = (180,180)\n",
    "BATCH_SIZE =32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8abaddc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 24959 files belonging to 2 classes.\n",
      "Using 19968 files for training.\n",
      "Found 24959 files belonging to 2 classes.\n",
      "Using 4991 files for validation.\n"
     ]
    }
   ],
   "source": [
    "train_df = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    PARENT,\n",
    "    validation_split = 0.2,\n",
    "    subset = \"training\",\n",
    "    seed = 42,\n",
    "    image_size = IMG_SIZE,\n",
    "    batch_size = BATCH_SIZE\n",
    ")\n",
    "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    PARENT,\n",
    "    validation_split = 0.2,\n",
    "    subset = \"validation\",\n",
    "    seed = 42,\n",
    "    image_size = IMG_SIZE,\n",
    "    batch_size = BATCH_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d3c207ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def get_lof_path(base_log_dir = os.path.join(\"logs\",\"fit\")):\n",
    "    uniquename = time.asctime().replace(\" \",\"_\").replace(\":\",\"\")\n",
    "    log_path = os.path.join(base_log_dir,uniquename)\n",
    "    return log_path\n",
    "log_dir =  get_lof_path()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6de3a970",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_writer = tf.summary.create_file_writer(logdir=log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c0076417",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 180, 180, 3) tf.Tensor([0 1 1 1 1 0 0 0 0 1 1 0 0 0 0 1 0 0 1 1 0 1 0 0 1 0 0 0 0 1 1 1], shape=(32,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "for images,labels in train_df.take(1):\n",
    "    print(images.shape,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "af779c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with file_writer.as_default():\n",
    "    images = np.reshape(images[10:30],(-1,180,180,3))\n",
    "    tf.summary.image(\"samples\",images.astype(\"uint8\"),max_outputs=25,step =0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "76263207",
   "metadata": {},
   "outputs": [],
   "source": [
    "AGUMENTATION_STEPS = [\n",
    "    tf.keras.layers.RandomFlip(\"horizontal\"),\n",
    "    tf.keras.layers.RandomRotation(0.1)\n",
    "]\n",
    "data_agumentation_layer = tf.keras.Sequential(AGUMENTATION_STEPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a480291f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
